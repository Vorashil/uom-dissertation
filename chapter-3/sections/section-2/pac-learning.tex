\section{PAC Learning}\label{sec:pac-learning}

In this section, we develop the Probably Approximately Correct (PAC) learning framework, which formalises the idea that a learning algorithm should output hypotheses that generalise well beyond the observed data. We begin by introducing the \emph{uniform convergence property}, a key concept ensuring that empirical error approximates true error uniformly across all hypotheses. We then discuss how the \emph{VC dimension} characterises the complexity of a hypothesis space and plays a decisive role in determining when uniform convergence holds. Finally, we connect these ideas through the Fundamental Theorem of Statistical Learning, which provides a precise equivalence between finite VC dimension and PAC learnability.

\subsection{Uniform Convergence Property}

A central difficulty in learning theory is that, for a fixed hypothesis $h$, the sample error $\hat{\operatorname{er}}_{z}(h)$ is only a random approximation of the true error $\operatorname{er}_{\mathbb{D}}(h)$. For PAC learning, it is not enough that this approximation holds for a single hypothesis; instead, we require that it holds \emph{uniformly} over the entire hypothesis space $\mathcal{H}$. This ensures that a learning algorithm, which selects its output hypothesis based on the data, is guaranteed to find a hypothesis whose empirical performance is close to its true performance. In short, uniform convergence is the key property that bridges finite-sample performance with generalisation guarantees.

\begin{definition}[Uniform Convergence Property, cf.~{\cite[Def.~2.4]{ShalevShwartzBenDavid2014}}]
    Suppose there exists $m_{\mathcal{H}} \in \mathbb{N}$ such that the map
    \[
        U = U(\mathcal{H}, m, \mathbb{D}) : \mathcal{Z}^m \to [0,1], \qquad
        z \mapsto \sup_{h \in \mathcal{H}} \bigl| \operatorname{er}_{\mathbb{D}}(h) - \hat{\operatorname{er}}_{z}(h) \bigr|
    \]
    is $\Sigma_{\mathcal{Z}}^m$-measurable for any $m \geq m_{\mathcal{H}}$ and any $\mathbb{D} \in \mathcal{D}$. Then $\mathcal{H}$ is said to have the \emph{uniform convergence property (UCP)} with respect to $\mathcal{D}$ if for every $\varepsilon, \delta \in (0,1)$ there exists $m_0 = m_0(\varepsilon,\delta) \geq m_{\mathcal{H}}$ such that for all $m \geq m_0$ and all $\mathbb{D} \in \mathcal{D}$,
    \[
        \mathbb{D}^m\!\left( \Bigl\{ z \in \mathcal{Z}^m \;\Big|\;
                          \sup_{h \in \mathcal{H}} \bigl| \operatorname{er}_{\mathbb{D}}(h) - \hat{\operatorname{er}}_{z}(h) \bigr| \leq \varepsilon \Bigr\} \right) \geq 1-\delta.
    \]
\end{definition}

\begin{remarknl}[Understanding uniform convergence parameters]
    \label{rem:pointwise-to-uniform}
    
    As discussed in Remark~\ref{rem:unbiased-not-enough}, the unbiasedness of sample error provides only a pointwise guarantee: for each fixed hypothesis $h$, the sample error converges to the true error as the sample size grows. The uniform convergence property is strongerâ€”it requires that the approximation holds simultaneously for all $h \in \mathcal{H}$.
    
    The definition involves three key parameters:
    \begin{itemize}
        \item $\varepsilon > 0$ is the \emph{accuracy parameter}: it bounds how far any sample error can deviate from its true error. Smaller $\varepsilon$ means tighter approximation.
        \item $\delta > 0$ is the \emph{confidence parameter}: with probability at least $1-\delta$, the uniform bound holds. Smaller $\delta$ means higher confidence.
        \item $m_0(\varepsilon, \delta)$ is the \emph{sample complexity}: the minimum sample size needed to achieve the desired accuracy and confidence. Crucially, this sample size works uniformly for all distributions in $\mathcal{D}$.
    \end{itemize}
    
    The property guarantees that for any sample of size $m \geq m_0$, with probability at least $1-\delta$ over the random draw of the sample, we have
    \[
        \sup_{h \in \mathcal{H}} \bigl|\hat{\operatorname{er}}_{z}(h) - \operatorname{er}_{\mathbb{D}}(h)\bigr| \leq \varepsilon.
    \]
    This uniform control is essential for learning: when an algorithm chooses the hypothesis with the smallest sample error, uniform convergence ensures this choice will also perform well on the underlying distribution, preventing overfitting due to random fluctuations in the sample.
\end{remarknl}

\noindent
This property guarantees that, with high probability, the sample error uniformly approximates the true error across the entire hypothesis class. As we will see, uniform convergence is the critical ingredient in proving PAC learnability: if $\mathcal{H}$ has UCP, then every empirical risk minimiser over $\mathcal{H}$ will generalise, which directly implies PAC learnability.

\subsection{PAC Learnability}

Having established the uniform convergence property, we now formally define PAC (Probably Approximately Correct) learnability. This framework, introduced by Valiant~\cite{Valiant1984}, captures the notion that a learning algorithm should produce hypotheses that generalise well with high probability.

\begin{definition}[PAC Learnability]
    \label{def:pac-learnable}
    A hypothesis space $\mathcal{H}$ is \emph{PAC learnable} with respect to a distribution family $\mathcal{D}$ if there exists a learning function $\mathcal{A}: \bigcup_{m \in \mathbb{N}} \mathcal{Z}^m \to \mathcal{H}$ and a function $m_{\mathcal{H}}: (0,1)^2 \to \mathbb{N}$ such that for every $\varepsilon, \delta \in (0,1)$, every $m \geq m_{\mathcal{H}}(\varepsilon, \delta)$, and every distribution $\mathbb{D} \in \mathcal{D}$, we have
    \[
        \mathbb{D}^m\!\left( \Bigl\{ z \in \mathcal{Z}^m \;\Big|\; \operatorname{er}_{\mathbb{D}}(\mathcal{A}(z)) \leq \inf_{h \in \mathcal{H}} \operatorname{er}_{\mathbb{D}}(h) + \varepsilon \Bigr\} \right) \geq 1-\delta.
    \]
\end{definition}

\begin{remarknl}[Interpretation of PAC learnability]
    
    The definition captures three essential aspects of successful learning:
    \begin{itemize}
        \item \emph{Probably}: With probability at least $1-\delta$ over the random sample, the algorithm succeeds. The confidence parameter $\delta$ controls the failure probability.
        \item \emph{Approximately}: The learned hypothesis has error within $\varepsilon$ of the best possible hypothesis in $\mathcal{H}$. The accuracy parameter $\varepsilon$ controls the approximation quality.
        \item \emph{Correct}: The comparison is with the optimal achievable error $\inf_{h \in \mathcal{H}} \operatorname{er}_{\mathbb{D}}(h)$, not perfect classification. This allows for inherent noise in the data.
    \end{itemize}
    
    The sample complexity function $m_{\mathcal{H}}(\varepsilon, \delta)$ determines how many samples are needed to achieve the desired accuracy and confidence. Importantly, this function depends only on $\mathcal{H}$, not on the specific distribution $\mathbb{D} \in \mathcal{D}$.
\end{remarknl}

