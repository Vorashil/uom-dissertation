\chapter{Learning Problem}

In this chapter, we build upon the discussion of VC-dimension and NIP properties from the previous chapter to explore their role within statistical learning theory. Our aim is to highlight the deep connections between model theory and learning theory, showing how combinatorial properties of definable sets naturally interact with notions of learnability. This chapter closely follows the perspective of Krapp and Wirth \cite{KrappWirth2021}, who provide a measure-theoretic analysis of the Fundamental Theorem of Statistical Learning. Their work presents the measurability assumptions required for rigorous proofs of PAC learnability, and we use their framework to bridge the concepts introduced earlier in model theory with the central results of learning theory.

\input{chapter-3/sections/section-1/learning-framework}
\input{chapter-3/sections/section-2/pac-learning}
\input{chapter-3/sections/section-3/fundamental-theorem}
\input{chapter-3/sections/section-4/connection-model-theory}